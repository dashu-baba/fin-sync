# Data Flow Architecture

This document details how data flows through the FinSync system across different use cases.

---

## Overview

FinSync has three primary data flows:
1. **Ingestion Flow**: PDF â†’ Parsed Data â†’ Indexed Documents
2. **Query Flow**: User Question â†’ Intent â†’ Search â†’ Answer
3. **Analytics Flow**: Aggregation Request â†’ ES|QL â†’ Visualizations

---

## 1. Document Ingestion Flow

### End-to-End Process

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User Upload â”‚
â”‚   PDF File  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Upload Service                   â”‚
â”‚  â€¢ Validate file type (.pdf)         â”‚
â”‚  â€¢ Check size limits (< 100MB)       â”‚
â”‚  â€¢ Generate session ID                â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Duplicate Detection               â”‚
â”‚  â€¢ Filename check                     â”‚
â”‚  â€¢ Content hash (SHA-256)             â”‚
â”‚  â€¢ Metadata check (accountNo + dates) â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ [If duplicate â†’ Reject]
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Storage Backend                   â”‚
â”‚  â€¢ LocalStorage (dev)                 â”‚
â”‚  â€¢ GCSStorage (prod)                  â”‚
â”‚  â€¢ Save file with session prefix      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. PDF Reader (PyPDF2)               â”‚
â”‚  â€¢ Extract text from all pages        â”‚
â”‚  â€¢ Handle encrypted PDFs (password)   â”‚
â”‚  â€¢ Preserve formatting where possible â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Raw text
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. Vertex AI Parser (Gemini)        â”‚
â”‚  â€¢ Send text + schema prompt          â”‚
â”‚  â€¢ Model: gemini-2.5-pro              â”‚
â”‚  â€¢ Extract structured JSON            â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Parsed JSON
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. Validation (Pydantic)             â”‚
â”‚  â€¢ ParsedStatement model              â”‚
â”‚  â€¢ Type checking                      â”‚
â”‚  â€¢ Date parsing                       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Validated data
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  7. Embedding Generation              â”‚
â”‚  â€¢ text-embedding-004                 â”‚
â”‚  â€¢ Embed statement descriptions       â”‚
â”‚  â€¢ Output: 768-dim vectors            â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Data + embeddings
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  8. Elastic Indexing                  â”‚
â”‚  â€¢ Index transactions                 â”‚
â”‚  â€¢ Index statement with vectors       â”‚
â”‚  â€¢ Bulk operations for performance    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  9. User Confirmation                 â”‚
â”‚  â€¢ Display success message            â”‚
â”‚  â€¢ Show parsed account info           â”‚
â”‚  â€¢ Transaction count                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Transformations

#### Step 1: Raw PDF â†’ Text
```python
# Input: Binary PDF file
file_bytes = uploaded_file.read()

# Output: Text string
text = extract_text_from_pdf(file_bytes, password="optional")
# Example: "Account Statement\nAccount No: 123456\n..."
```

#### Step 2: Text â†’ Structured JSON
```python
# Input: Raw text
text = "Account Statement\nAccount No: 123456\nDate: 2025-01..."

# Gemini prompt includes schema definition
parsed_json = parse_with_vertex_ai(text, model="gemini-2.5-pro")

# Output: Structured JSON
{
  "accountName": "John Doe",
  "accountNo": "123456",
  "statements": [...]
}
```

#### Step 3: JSON â†’ Elastic Documents
```python
# Input: Parsed statement
parsed = ParsedStatement(accountName="John Doe", ...)

# Output 1: Transaction documents (flat)
[
  {
    "accountNo": "123456",
    "statementDate": "2025-01-02",
    "statementAmount": 5000.00,
    "statementType": "credit",
    "statementDescription": "Salary",
    "statementBalance": 12500.00
  },
  ...
]

# Output 2: Statement document (with vector)
{
  "accountNo": "123456",
  "statementFrom": "2025-01-01",
  "statementTo": "2025-01-31",
  "rawText": "Account Statement...",
  "desc_vector": [0.123, -0.456, ...],  # 768 dimensions
  "statements": [nested transactions]
}
```

### Error Handling

| Error | Recovery Strategy |
|-------|-------------------|
| **Invalid PDF** | Show error, reject upload |
| **Password-protected** | Prompt for password |
| **Parse failure** | Retry with different prompt, or manual review |
| **Duplicate detected** | Reject with explanation, show existing file |
| **Indexing failure** | Retry with exponential backoff, log error |

---

## 2. Query Processing Flow

### Intent Classification Path

```
User Query: "How much did I spend on groceries last month?"
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Intent Classification             â”‚
â”‚  â€¢ Model: Gemini 2.5 Pro              â”‚
â”‚  â€¢ Prompt: INTENT_ROUTER_PROMPT       â”‚
â”‚  â€¢ Output: IntentResponse             â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Classification result
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Confidence Check                  â”‚
â”‚  â€¢ If < 0.75 â†’ Confirmation dialog    â”‚
â”‚  â€¢ If needsClarification â†’ Ask user   â”‚
â”‚  â€¢ Else â†’ Proceed                     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Confirmed intent
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Intent Execution Router           â”‚
â”‚  â€¢ aggregate                          â”‚
â”‚  â€¢ aggregate_filtered_by_text         â”‚
â”‚  â€¢ text_qa                            â”‚
â”‚  â€¢ provenance                         â”‚
â”‚  â€¢ trend                              â”‚
â”‚  â€¢ listing                            â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Route to executor
       â–¼
[See intent-specific flows below]
```

### Intent-Specific Flows

#### **aggregate Intent**
```
Query: "Total spending last month"
    â†“
Extract filters: {
  date_from: "2024-12-01",
  date_to: "2024-12-31",
  type: "debit"
}
    â†“
Build ES|QL query:
```
```sql
FROM finsync-transactions
| WHERE statementDate >= "2024-12-01" 
  AND statementDate <= "2024-12-31"
  AND statementType == "debit"
| STATS 
    total = SUM(statementAmount),
    count = COUNT(*),
    avg = AVG(statementAmount)
```
```
    â†“
Execute on Elastic â†’ Results
    â†“
Compose answer: "You spent $3,245.00 last month across 47 transactions."
```

#### **aggregate_filtered_by_text Intent**
```
Query: "How much did I spend on groceries?"
    â†“
Step 1: Semantic Search on Statements
    â†“
Build hybrid query (BM25 + kNN):
  - Keyword: "groceries"
  - Vector: embedding_of("groceries")
    â†“
Execute â†’ Get matching statements
    â†“
Extract merchant terms: ["Walmart", "Kroger", "Whole Foods"]
    â†“
Step 2: Aggregate Transactions
    â†“
Build ES|QL with derived filters:
```
```sql
FROM finsync-transactions
| WHERE statementDescription LIKE "Walmart" 
   OR statementDescription LIKE "Kroger"
   OR statementDescription LIKE "Whole Foods"
| STATS total = SUM(statementAmount)
```
```
    â†“
Compose answer: "You spent $875.50 on groceries at Walmart, Kroger, and Whole Foods."
```

#### **text_qa Intent**
```
Query: "What fees are mentioned in my statement?"
    â†“
Step 1: Hybrid Search on Statements
    â†“
BM25 query: "fees"
kNN query: embedding_of("What fees are mentioned")
    â†“
RRF Fusion (k=60):
  - Combine keyword + semantic results
  - Score = 1/(k + rank)
    â†“
Top 5 results with provenance
    â†“
Step 2: Generate Answer with Gemini
    â†“
Prompt: "Answer this question based on context: [results]"
    â†“
Answer: "Your statement mentions the following fees: overdraft fee ($35), monthly service fee ($10)..."
    â†“
Append citations: [Statement 1, Page 2]
```

### Clarification Flow

```
User Query: "Show my spending"
    â†“
Classify intent â†’ confidence = 0.68
    â†“
[Low confidence detected]
    â†“
Display confirmation dialog:
  "I understood: Aggregate expenses. Is this correct?"
  [âœ… Yes] [âŒ No, let me rephrase]
    â†“
If Yes â†’ Proceed with execution
If No â†’ Return to input
```

```
User Query: "bkash transactions"
    â†“
Classify intent â†’ needsClarification = true
    â†“
clarifyQuestion: "Which time period?"
    â†“
Display clarification dialog:
  "ğŸ¤” Which time period are you interested in?"
  [Input: "last month"]
  [Continue] [Skip]
    â†“
Re-classify with context:
  - Original: "bkash transactions"
  - Clarification: "last month"
  - Cumulative: "bkash transactions last month"
    â†“
New intent with higher confidence â†’ Execute
```

---

## 3. Analytics Dashboard Flow

```
User Opens Analytics Page
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Initialize Filters                â”‚
â”‚  â€¢ Account: All / Specific            â”‚
â”‚  â€¢ Date range: Custom / Presets       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Query Monthly Aggregates          â”‚
â”‚  â€¢ ES|QL query with date_histogram    â”‚
â”‚  â€¢ Group by month                     â”‚
â”‚  â€¢ Sum income, expenses                â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Aggregation results
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Transform Data for Plotly         â”‚
â”‚  â€¢ Convert to DataFrame format        â”‚
â”‚  â€¢ Calculate net = income - expenses  â”‚
â”‚  â€¢ Format dates                       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Chart data
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. Generate Visualizations           â”‚
â”‚  â€¢ Line chart: Income vs Expenses     â”‚
â”‚  â€¢ Bar chart: Net flow by month       â”‚
â”‚  â€¢ Pie chart: Account distribution    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Plotly figures
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. Render in Streamlit               â”‚
â”‚  â€¢ st.plotly_chart()                  â”‚
â”‚  â€¢ Interactive hover/zoom             â”‚
â”‚  â€¢ Responsive layout                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Session State Management

### Session Variables

```python
{
    # File upload tracking
    "uploaded_files": list,
    "session_id": str,
    
    # Chat conversation
    "chat_history": list[dict],
    "pending_query": str | None,
    
    # Clarification state
    "clarification_mode": str | None,  # "confirm" | "clarify"
    "pending_intent": IntentResponse | None,
    "current_conversation": list,
    
    # Analytics filters
    "selected_account": str,
    "date_range": tuple[date, date],
    
    # UI state
    "show_intent_details": bool,
    "active_tab": str
}
```

### State Transitions

```
IDLE
  â†“ [User uploads file]
UPLOADING
  â†“ [File saved]
PARSING
  â†“ [Parse complete]
IDLE

IDLE
  â†“ [User enters query]
CLASSIFYING
  â†“ [Low confidence]
AWAITING_CONFIRMATION
  â†“ [User confirms]
EXECUTING
  â†“ [Results ready]
IDLE

IDLE
  â†“ [User enters query]
CLASSIFYING
  â†“ [Needs clarification]
AWAITING_CLARIFICATION
  â†“ [User provides info]
RECLASSIFYING
  â†“ [Clear now]
EXECUTING
  â†“ [Results ready]
IDLE
```

---

## Performance Characteristics

### Latency Breakdown

**Document Upload**:
```
File upload: 100-500ms (network)
PDF extraction: 200-1000ms (file size dependent)
Vertex AI parsing: 3-10 seconds (complexity dependent)
Embedding generation: 500-2000ms (batch size)
Elastic indexing: 100-500ms (document count)
---
Total: 4-14 seconds
```

**Query Processing**:
```
Intent classification: 500-2000ms (Gemini)
Elastic search: 20-200ms (query complexity)
Answer generation: 1-3 seconds (Gemini)
---
Total: 2-5 seconds
```

**Analytics Loading**:
```
ES|QL aggregation: 50-300ms (data size)
Chart rendering: 100-500ms (browser)
---
Total: < 1 second
```

### Optimization Opportunities

1. **Caching**: Cache frequent queries in Redis
2. **Batching**: Batch multiple embeddings in one call
3. **Streaming**: Stream Gemini responses for faster perceived latency
4. **Precomputation**: Pre-compute common aggregations
5. **Lazy Loading**: Load analytics charts on demand

---

## Error Propagation

```
Component Error
    â†“
Log with context (logger.error)
    â†“
Wrap in user-friendly message
    â†“
Display in UI with error icon
    â†“
Offer recovery actions:
  - Retry
  - Modify query
  - Contact support
```

### Example Error Handling

```python
try:
    result = execute_aggregate(filters)
except ElasticsearchException as e:
    log.error(f"Elastic query failed: {e}", exc_info=True)
    return {
        "error": "Search service unavailable. Please try again.",
        "technical_details": str(e)  # Only in dev mode
    }
except Exception as e:
    log.exception("Unexpected error in aggregation")
    return {
        "error": "An unexpected error occurred. Our team has been notified."
    }
```

---

## Data Consistency

### Eventual Consistency

Elastic indexing is **near-realtime**:
- Documents indexed within 1 second (refresh_interval)
- Queries may not immediately see new documents
- Analytics use refresh to ensure consistency

### Transaction Boundaries

No distributed transactions. Operations are:
1. **Idempotent**: Safe to retry
2. **Atomic per-index**: Single document operations
3. **Best-effort**: Duplicate detection catches most issues

---

## Conclusion

FinSync's data flows are designed for:
- **Reliability**: Multiple layers of validation
- **Performance**: Async operations, efficient queries
- **Observability**: Comprehensive logging at each step
- **User Experience**: Clear feedback, graceful error handling

Each flow prioritizes user experience while maintaining data integrity.

---

**Related**: [System Overview](./OVERVIEW.md) | [Intent System](./INTENT_SYSTEM.md)

